#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import multiprocessing
import subprocess
import argparse
import pandas as pd
from nBee import Utilities, SampleDataParser, SampleDataLine, RefDataParser, RefDataLine


class Initializer:
    def __init__(self):
        self._namespace = self._parse_args()
        self.sampledata = self._namespace.sampledata
        self.refdata = self._namespace.refdata
        self.chunk_number = self._namespace.chunk
        self.prefix = self._namespace.prefix
        self.suffix = self._namespace.suffix
        self.debugging_bool = self._namespace.debug
        self.output = self._namespace.output
    @staticmethod
    def _parse_args():
        starting_parser = argparse.ArgumentParser(description="The script to detect nBee or refdata2schedule pipeline faults")
        starting_parser.add_argument("-s", "--sampledata", required=True,
                                     help="Input list containing two tab-delimited columns for colorspace or non-colorspace sequences and three for paired-end sequences: sample name and absolute path(s). May contain a header")
        starting_parser.add_argument("-r", "--refdata", required=True,
                                     help="Refdata generated by 'cook_the_reference.py' script containing link to annotation file in 6th column")
        starting_parser.add_argument("-c", "--chunk", default=0, type=int,
                                     help="(Optional) Chunk number (zero-bassed), 0 by default")
        starting_parser.add_argument("-p", "--prefix", required=True,
                                     help="Output files prefix before sample name, e.g '/path/to/coverage/'. \nOutput would be placed into parent directory")
        starting_parser.add_argument("-s", "--suffix", required=True,
                                     help="Output files suffix after sample name, e.g 'coverage_mask.extension'")
        starting_parser.add_argument("-d", "--debug", default=False, action='store_true',
                                     help="Create debugging table")
        starting_parser.add_argument("-o", "--output", required=True,
                                     help="Path to look for coverage files. Must contain subdirectories created by 'nBee.py' script")
        return starting_parser.parse_args()


def get_wc_l(file_name):
    if os.path.isfile(file_name):
        try:
            return int(subprocess.getoutput("wc -l < {}".format(file_name)).split('\n')[0])
        except ValueError:
            print("Failed to count lines for file: '{}'")
            raise
    else:
        return 0


def dict2pd_series(dictionary):
    output = pd.Series()
    for key in dictionary:
        output.at[key] = dictionary[key]
    return output


def process_sampledata_line(sampledata_line):
    coverage_path = "{a}{b}{c}".format(a=mainInitializer.prefix, b=sampledata_line.name, c=mainInitializer.suffix)
    # Coverage file contains a header
    coverage_rows_count = get_wc_l(coverage_path) - 1
    d = {"sample_name": sampledata_line.name,
         "source_paths": ";".join(sampledata_line.raw_reads_files_list),
         "is_source_exists": len(sampledata_line) == len(sampledata_line.raw_reads_files_list),
         "coverage_path": coverage_path,
         "is_coverage_exists": os.path.isfile(coverage_path),
         "is_coverage_valid": coverage_rows_count == referenceRowsCount}
    return dict2pd_series(d)


def assembly_df_from_series_list(series_list, sorting_col_name):
    output_df = pd.DataFrame()
    for series in series_list:
        if len(output_df) == 0:
            output_df = pd.DataFrame([series])
        else:
            output_df = output_df.append(series, ignore_index=True)
    return output_df.sort_values(sorting_col_name)


if __name__ == '__main__':
    mainInitializer = Initializer()
    refDataParser = RefDataParser(mainInitializer.refdata)
    refData = refDataParser.get_refdata_line_by_index(mainInitializer.chunk_number)
    referenceRowsCount = get_wc_l(refData.samtools_index_file)
    sampleDataParser = SampleDataParser(mainInitializer.sampledata)
    sampleDataLinesList = sampleDataParser.get_parsed_list()
    verifiedDataFrame = assembly_df_from_series_list(series_list=Utilities.multi_core_queue(func=process_sampledata_line, queue=sampleDataLinesList),
                                                     sorting_col_name="sample_name")
    noSampleDataDF = verifiedDataFrame.loc[verifiedDataFrame["is_source_exists"] == False]
    toDoDF = verifiedDataFrame.loc[(verifiedDataFrame["is_source_exists"] == True) & (verifiedDataFrame["is_coverage_valid"] == False)]
    if len(noSampleDataDF) > 0:
        print("""
              Warning! The sources of following samples have not been found: '{a}'.
              Please check the provided file: '{b}'
              """.format(a="', '".join(noSampleDataDF["sample_name"].values.tolist()), b=mainInitializer.sampledata))
    timeString = Utilities.get_time()
    outputList = [i.export() for i in sampleDataLinesList if i.name in toDoDF["sample_name"].values.tolist()]
    outputDir = Utilities.ends_with_slash(os.path.dirname(mainInitializer.prefix))
    outputSampleDataFileName = "{a}{b}.sampledata".format(a=outputDir, b=timeString)
    Utilities.dump_string(string="\n".join(outputList), file=outputSampleDataFileName)
    if mainInitializer.debugging_bool:
        verifiedDataFrame.to_csv("{a}{b}_debug.tsv".format(a=outputDir, b=timeString), sep='\t', header=True, index=False)
    print("""
          Done. \nFiles to process: {} \nDumped sample data: {}
          """.format(len(toDoDF), outputSampleDataFileName))
